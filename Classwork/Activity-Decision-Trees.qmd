---
title: "Classification: Decision Trees"
author: "YOUR NAME HERE"
format: 
  html:
    code-fold: true
    code-line-numbers: true
    code-tools: true
    self-contained: true
editor: visual
execute:
  message: false
---

```{r, eval = TRUE, version = "none"}
templar::versions_quarto_multilingual(global_eval = FALSE, to_jupyter = TRUE, warn_edit = FALSE)
```

## Setup

Declare your libraries:

```{r, version = "R"}
#| label: libraries-r
#| include: false
library(tidyverse)
library(tidymodels)
library(glmnet)
library(discrim)
library(rpart)
library(rpart.plot)
```

```{python, version = "python"}
#| label: libraries-py
#| include: false
import pandas as pd

import seaborn as sns
import matplotlib.pyplot as plt


from sklearn.linear_model import LinearRegression, LogisticRegression
from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier

from sklearn.metrics import r2_score, confusion_matrix, accuracy_score, precision_score, recall_score, roc_auc_score, make_scorer

from sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder
from sklearn.compose import make_column_transformer
from sklearn.pipeline import Pipeline, make_pipeline

from sklearn.model_selection import cross_val_score, GridSearchCV, KFold

from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis

from sklearn.tree import DecisionTreeClassifier, plot_tree
```


# Setup

Today's data concerns strains of cannabis, which have the types of `sativa`, `indica`, or `hybrid`:

```{r, version = "R"}

cann <- read_csv("https://www.dropbox.com/s/s2a1uoiegitupjc/cannabis_full.csv?dl=1")


cann <- cann %>%
  mutate(
    Type = factor(Type)
  ) %>%
  drop_na()

cann_cvs <- vfold_cv(cann, v = 5)

cann_recipe <- recipe(Type ~ ., 
                     data = cann) %>%
  step_rm(Strain, Effects, Flavor)
```


```{python, version = "python"}

cann = pd.read_csv("https://www.dropbox.com/s/s2a1uoiegitupjc/cannabis_full.csv?dl=1")


cann["Type"] = cann["Type"].astype("category")
cann = cann.dropna() 

cann = cann.drop(columns = ["Strain", "Effects", "Flavor"])

cann_X = cann.drop(columns = ["Type"])

cross_validation = KFold(n_splits=10)

```



## Logistic Regression

Does not work:

```{r, version = "R"}
logit_mod <- logistic_reg() %>%
  set_engine("glm") %>%
  set_mode("classification")

logit_wflow <- workflow() %>%
  add_recipe(cann_recipe) %>%
  add_model(logit_mod)

logit_fit <- logit_wflow %>%
  fit_resamples(cann_cvs)

```

```{python, version = "python"}
logit_wflow = make_pipeline(
  LogisticRegression()
)

logit_scores = cross_val_score(logit_wflow, cann_X, cann["Type"], scoring="accuracy", cv=cross_validation)

```


## Discriminant Analysis

Does work:

```{r, version = "R"}
lda_mod <- discrim_linear() %>%
  set_engine("MASS") %>%
  set_mode("classification")

lda_wflow <- workflow() %>%
  add_recipe(cann_recipe) %>%
  add_model(lda_mod)

lda_fit <- lda_wflow %>%
  fit_resamples(cann_cvs)

```

```{python, version = "python"}
lda_wflow = make_pipeline(
  LinearDiscriminantAnalysis()
)

lda_scores = cross_val_score(lda_wflow, cann_X, cann["Type"], scoring="accuracy", cv=cross_validation)

lda_scores

```



## KNN

Does work:

```{r, version = "R"}
knn_mod <- nearest_neighbor(neighbors = 5) %>%
  set_engine("kknn") %>%
  set_mode("classification")

knn_wflow <- workflow() %>%
  add_recipe(cann_recipe) %>%
  add_model(knn_mod)

knn_fit <- knn_wflow %>%
  fit_resamples(cann_cvs)

```

```{python, version = "python"}

knn_wflow = make_pipeline(
  KNeighborsClassifier(n_neighbors = 5)
)

knn_scores = cross_val_score(knn_wflow, cann_X, cann["Type"], scoring="accuracy", cv=cross_validation)

knn_scores

```

```{python, version = "python"}

knn_scores = cross_val_score(knn_wflow, cann_X, cann["Type"], scoring="precision_macro", cv=cross_validation)

knn_scores

knn_scores = cross_val_score(knn_wflow, cann_X, cann["Type"], scoring="recall_macro", cv=cross_validation)

knn_scores


knn_scores = cross_val_score(knn_wflow, cann_X, cann["Type"], scoring="roc_auc_ovr", cv=cross_validation)

knn_scores


```

```{r, version = "R"}
knn_fit <- knn_wflow %>%
  fit_resamples(cann_cvs,
                metrics = metric_set(accuracy, roc_auc, precision, recall))


knn_fit %>% collect_metrics()
```

## Decision Trees

```{r, version = "R"}
cann %>%
  ggplot(aes(x = factor(Energetic), fill = factor(Type))) +
  geom_bar(position = "fill")
```

```{r, version = "R"}
cann %>%
  ggplot(aes(x = factor(Pineapple), fill = Type)) +
  geom_bar(position = "fill")
```


```{r, version = "R"}
tree_mod <- decision_tree() %>%
  set_engine("rpart") %>%
  set_mode("classification")

tree_wflow <- workflow() %>%
  add_recipe(cann_recipe) %>%
  add_model(tree_mod)
```


```{r, version = "R"}
tree_fit <- tree_wflow %>%
  fit_resamples(cann_cvs,
                metrics = metric_set(accuracy, roc_auc, precision, recall))


tree_fit %>% collect_metrics()
```

```{python, version = "python"}
tree_wflow = make_pipeline(
  DecisionTreeClassifier()
)

tree_acc = cross_val_score(tree_wflow, cann_X, cann["Type"], scoring="accuracy", cv=cross_validation)

tree_prec = cross_val_score(tree_wflow, cann_X, cann["Type"], scoring="precision_macro", cv=cross_validation)

tree_rec = cross_val_score(tree_wflow, cann_X, cann["Type"], scoring="recall_macro", cv=cross_validation)

tree_roc = cross_val_score(tree_wflow, cann_X, cann["Type"], scoring="roc_auc_ovr", cv=cross_validation)

tree_acc.mean()
tree_prec.mean()
tree_rec.mean()
tree_roc.mean()
```


```{r, version = "R"}

tree_fit_1 <- tree_wflow %>%
  fit(cann)

tree_fit_1$fit
```

#### Plot of Tree

```{r, version = "R"}
tree_fitted <- tree_fit_1 %>% 
  pull_workflow_fit()

rpart.plot(tree_fitted$fit)
```

```{python, version = "python"}

tree = DecisionTreeClassifier()

tree.fit(cann_X, cann["Type"])

plot_tree(tree)


```

#### Tuning

```{r, version = "R"}
tree_grid <- grid_regular(cost_complexity(),
                          tree_depth(),
                          min_n(), 
                          levels = 2)


tree_mod <- decision_tree(cost_complexity = tune(),
                          tree_depth = tune(),
                          min_n = tune()) %>%
  set_engine("rpart") %>%
  set_mode("classification")

tree_wflow <- workflow() %>%
  add_recipe(cann_recipe) %>%
  add_model(tree_mod)

tree_grid_search <-
  tune_grid(
    tree_wflow,
    resamples = cann_cvs,
    grid = tree_grid
  )

tuning_metrics <- tree_grid_search %>% collect_metrics()
```


```{r, version = "R"}
tuning_metrics %>%
  filter(.metric == "accuracy") %>%
  slice_max(mean)
```

```{r, version = "R"}
tuning_metrics %>%
  filter(.metric == "roc_auc") %>%
  slice_max(mean)
```


```{python, version = "python"}

tree_grid = [
  {"decisiontreeclassifier__ccp_alpha": [0.1, 0.0000001]}, 
  {"decisiontreeclassifier__max_depth": [1, 15]},
  {"decisiontreeclassifier__min_samples_split": [2, 40]}
  ]


grid_search = GridSearchCV(tree_wflow,
                           param_grid=tree_grid,
                           scoring=scoring,
                           cv=10)
                           
grid_search.fit(cann_X, cann["Type"])

grid_search.best_estimator_

```


## Your Turn

#### Fit a final model with the selected hyperparameters
#### Report some metrics for the final model
#### Plot the tree (code is provided)
#### Interpret the first two levels of splits in plain English.


