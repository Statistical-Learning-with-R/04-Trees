---
title: "Classification 2"
author: "YOUR NAME HERE"
output: html_document
# Warning:  File created automatically
# Do NOT edit this file directly, as it may be overwritten.
---

```{r, include = FALSE}
```
```{r setup, include=FALSE}
library(tidyverse)
library(tidymodels)
library(kknn)
library(glmnet)
library(discrim)
library(rpart)
library(rpart.plot)
```

# Setup

Today's data concerns strains of cannabis, which have the types of `sativa`, `indica`, or `hybrid`:

```{r, echo = FALSE, message = FALSE}

cann <- read_csv("https://www.dropbox.com/s/s2a1uoiegitupjc/cannabis_full.csv?dl=1")

cann <- cann %>%
  mutate(
    Type = factor(Type)
  ) %>%
  drop_na()

cann_cvs <- vfold_cv(cann, v = 5)

cann_recipe <- recipe(Type ~ ., 
                     data = cann) %>%
  step_rm(Strain, Effects, Flavor)
```

## Logistic Regression

```{r, error = TRUE}
logit_mod <- logistic_reg() %>%
  set_engine("glm") %>%
  set_mode("classification")

logit_wflow <- workflow() %>%
  add_recipe(cann_recipe) %>%
  add_model(logit_mod)

logit_fit <- logit_wflow %>%
  fit_resamples(cann_cvs)

```

## Discriminant Analysis

```{r, error = TRUE}
lda_mod <- discrim_linear() %>%
  set_engine("MASS") %>%
  set_mode("classification")

lda_wflow <- workflow() %>%
  add_recipe(cann_recipe) %>%
  add_model(lda_mod)

lda_fit <- lda_wflow %>%
  fit_resamples(cann_cvs)

```

## KNN

```{r, error = TRUE}
knn_mod <- nearest_neighbor(neighbors = 5) %>%
  set_engine("kknn") %>%
  set_mode("classification")

knn_wflow <- workflow() %>%
  add_recipe(cann_recipe) %>%
  add_model(knn_mod)

knn_fit <- knn_wflow %>%
  fit_resamples(cann_cvs)

```

```{r}
knn_fit <- knn_wflow %>%
  fit_resamples(cann_cvs,
                metrics = metric_set(accuracy, roc_auc, precision, recall))

knn_fit %>% collect_metrics()
```

## Decision Trees

```{r, echo = FALSE}
cann %>%
  ggplot(aes(x = factor(Energetic), fill = factor(Type))) +
  geom_bar(position = "fill")
```

```{r, echo = FALSE}
cann %>%
  ggplot(aes(x = factor(Pineapple), fill = Type)) +
  geom_bar(position = "fill")
```

```{r, error = TRUE}
tree_mod <- decision_tree() %>%
  set_engine("rpart") %>%
  set_mode("classification")

tree_wflow <- workflow() %>%
  add_recipe(cann_recipe) %>%
  add_model(tree_mod)
```

```{r}
tree_fit <- tree_wflow %>%
  fit_resamples(cann_cvs,
                metrics = metric_set(accuracy, roc_auc, precision, recall))

tree_fit %>% collect_metrics()
```

```{r, echo = FALSE}

tree_fit_1 <- tree_wflow %>%
  fit(cann)

tree_fit_1$fit
```

#### Plot of Tree

```{r, echo = FALSE, warning = FALSE}
tree_fitted <- tree_fit_1 %>% 
  pull_workflow_fit()

rpart.plot(tree_fitted$fit)
```
#### Tuning

```{r, cache = TRUE}
tree_grid <- grid_regular(cost_complexity(),
                          tree_depth(),
                          min_n(), 
                          levels = 2)

tree_mod <- decision_tree(cost_complexity = tune(),
                          tree_depth = tune(),
                          min_n = tune()) %>%
  set_engine("rpart") %>%
  set_mode("classification")

tree_wflow <- workflow() %>%
  add_recipe(cann_recipe) %>%
  add_model(tree_mod)

tree_grid_search <-
  tune_grid(
    tree_wflow,
    resamples = cann_cvs,
    grid = tree_grid
  )

tuning_metrics <- tree_grid_search %>% collect_metrics()
```

```{r}
tuning_metrics %>%
  filter(.metric == "accuracy") %>%
  slice_max(mean)
```

```{r}
tuning_metrics %>%
  filter(.metric == "roc_auc") %>%
  slice_max(mean)
```

## Your Turn

#### Fit a final model with the selected hyperparameters
#### Report some metrics for the final model
#### Plot the tree (code is provided)
#### Interpret the first two levels of splits in plain English.

