---
title: "Classification: Decision Trees"
author: "YOUR NAME HERE"
format: 
  html:
    code-fold: true
    code-line-numbers: true
    code-tools: true
    self-contained: true
editor: visual
execute:
  message: false
---

## Setup

Declare your libraries:

```{r}
#| label: libraries-r
#| include: false
library(tidyverse)
library(tidymodels)
library(glmnet)
library(discrim)
library(rpart)
library(rpart.plot)
```


# Setup

Today's data concerns strains of cannabis, which have the types of `sativa`, `indica`, or `hybrid`:

```{r}

cann <- read_csv("https://www.dropbox.com/s/s2a1uoiegitupjc/cannabis_full.csv?dl=1")

cann <- cann %>%
  mutate(
    Type = factor(Type)
  ) %>%
  drop_na()

cann_cvs <- vfold_cv(cann, v = 5)

cann_recipe <- recipe(Type ~ ., 
                     data = cann) %>%
  step_rm(Strain, Effects, Flavor)
```


## Logistic Regression

Does not work:

```{r}
logit_mod <- logistic_reg() %>%
  set_engine("glm") %>%
  set_mode("classification")

logit_wflow <- workflow() %>%
  add_recipe(cann_recipe) %>%
  add_model(logit_mod)

logit_fit <- logit_wflow %>%
  fit_resamples(cann_cvs)

```


## Discriminant Analysis

Does work:

```{r}
lda_mod <- discrim_linear() %>%
  set_engine("MASS") %>%
  set_mode("classification")

lda_wflow <- workflow() %>%
  add_recipe(cann_recipe) %>%
  add_model(lda_mod)

lda_fit <- lda_wflow %>%
  fit_resamples(cann_cvs)

```


## KNN

Does work:

```{r}
knn_mod <- nearest_neighbor(neighbors = 5) %>%
  set_engine("kknn") %>%
  set_mode("classification")

knn_wflow <- workflow() %>%
  add_recipe(cann_recipe) %>%
  add_model(knn_mod)

knn_fit <- knn_wflow %>%
  fit_resamples(cann_cvs)

```



```{r}
knn_fit <- knn_wflow %>%
  fit_resamples(cann_cvs,
                metrics = metric_set(accuracy, roc_auc, precision, recall))

knn_fit %>% collect_metrics()
```

## Decision Trees

```{r}
cann %>%
  ggplot(aes(x = factor(Energetic), fill = factor(Type))) +
  geom_bar(position = "fill")
```

```{r}
cann %>%
  ggplot(aes(x = factor(Pineapple), fill = Type)) +
  geom_bar(position = "fill")
```

```{r}
tree_mod <- decision_tree() %>%
  set_engine("rpart") %>%
  set_mode("classification")

tree_wflow <- workflow() %>%
  add_recipe(cann_recipe) %>%
  add_model(tree_mod)
```

```{r}
tree_fit <- tree_wflow %>%
  fit_resamples(cann_cvs,
                metrics = metric_set(accuracy, roc_auc, precision, recall))

tree_fit %>% collect_metrics()
```


```{r}

tree_fit_1 <- tree_wflow %>%
  fit(cann)

tree_fit_1$fit
```

#### Plot of Tree

```{r}
tree_fitted <- tree_fit_1 %>% 
  pull_workflow_fit()

rpart.plot(tree_fitted$fit)
```


#### Tuning

```{r}
tree_grid <- grid_regular(cost_complexity(),
                          tree_depth(),
                          min_n(), 
                          levels = 2)

tree_mod <- decision_tree(cost_complexity = tune(),
                          tree_depth = tune(),
                          min_n = tune()) %>%
  set_engine("rpart") %>%
  set_mode("classification")

tree_wflow <- workflow() %>%
  add_recipe(cann_recipe) %>%
  add_model(tree_mod)

tree_grid_search <-
  tune_grid(
    tree_wflow,
    resamples = cann_cvs,
    grid = tree_grid
  )

tuning_metrics <- tree_grid_search %>% collect_metrics()
```

```{r}
tuning_metrics %>%
  filter(.metric == "accuracy") %>%
  slice_max(mean)
```

```{r}
tuning_metrics %>%
  filter(.metric == "roc_auc") %>%
  slice_max(mean)
```


## Your Turn

#### Fit a final model with the selected hyperparameters
#### Report some metrics for the final model
#### Plot the tree (code is provided)
#### Interpret the first two levels of splits in plain English.

